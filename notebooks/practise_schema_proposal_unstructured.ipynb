{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Np0plMPXRvoq"
   },
   "source": [
    "# Lesson 7 - Schema Proposal for Unstructured Data\n",
    "\n",
    "In this lesson, you will design agents that propose how to extract information from unstructured data.\n",
    "\n",
    "You'll learn:\n",
    "- how \"named entity recognition\" can be used to identify the people, places and things\n",
    "- how facts can be extracted as a \"triple\" of subject, predicate and object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b>To access the helper.py, neo4j_for_adk.py and tools.py files :</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/entire_solution.png\" width=\"500\">\n",
    "\n",
    "Two agents to propose data extraction from unstructured data: a \"named entity recognition\" agent and a \"fact extraction\" agent:\n",
    "\n",
    "- Input: `approved_user_goal`, `approved_files`, `approved_construction_plan`\n",
    "- Output: \n",
    "    - `approved_entity_types` describing the type of entities that could be extracted from the unstructured data\n",
    "    - `approved_fact_types` describing how those entities can be related in a fact triple\n",
    "- Tools: `get_approved_user_goal`, `get_approved_files`, `get_well_known_types`, `sample_file`, `set_proposed_entities`, `get_proposed_entities`, `approve_proposed_entities`, `add_proposed_fact`, `get_proposed_facts`, `approve_proposed_facts`\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "<img src=\"images/workflow.png\" width=\"500\">\n",
    "\n",
    "Named entity recognition:\n",
    "\n",
    "1. The context is initialized with an `approved_user_goal`, `approved_files` and an `approved_construction_plan`\n",
    "2. The agent analyzes unstructured data files, looking for relevant entity types \n",
    "3. The agent proposes a list of entity types, seeking user approval\n",
    "\n",
    "Fact extraction:\n",
    "\n",
    "1. The context now includes `approved_entity_types`\n",
    "2. The agent analyzes unstructured data files, looking for how those entities can be saved as fact triples\n",
    "3. The agent proposes fact types, seeking user approval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual import of needed libraries, loading of environment variables, and connection to Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 301,
    "id": "sbwxKypOSBkN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 184,
    "id": "MI_qvZJrSJuR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Named Entity Recognition (NER) Sub-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NER agent is responsible for proposing entities that could be extracted from the unstructured data files.\n",
    "\n",
    "An entity is a person, place or thing that is relevant to the user's goal.\n",
    "\n",
    "There are two general kinds of entities:\n",
    "\n",
    "1. Well-known entities: these closely correlate with nodes in the existing structured data\n",
    "   - in our example, this would be things like Products, Parts and Suppliers\n",
    "2. Discovered entities: these are entities that are not pre-defined, but are mentioned in the markdown text\n",
    "    - in the product reviews, this may may Reviewers, product complaints, or product features\n",
    "\n",
    "The general goal of the NER agent is to analyze the markdown files and propose entities that are \n",
    "relevant to the user goal of root-cause analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1. Agent Instructions (NER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 371
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 286
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 131
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2. Tool Definitions (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in previous lessons, you'll define some tools that explictly follow\n",
    "a propose then approve pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 490
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"well-known entities\" are based on existing node labels used during graph construction.\n",
    "\n",
    "This helper tool will get the existing node labels from the approved construction plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 167
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full toolset includes some existing tools that you'll import\n",
    "plus the extra tools you just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 150
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what the NER agent is working with, use the sample_file tool to look\n",
    "at one of the markdown files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 82
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The markdown has product reviews from multiple users that include a rating, the review and their username.\n",
    "\n",
    "For root-cause analysis, you'll be interested in reviews that are negative and report product issues\n",
    "like quality, challenges in assembly, or reliability.\n",
    "\n",
    "We won't provide explicit instructions about product reviews to the agent, instead relying\n",
    "on a combination of the stated user goal along with instruction to find entity types\n",
    "that would support that user goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3. Construct the Sub-agent (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 184
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial state is important in this phase, as the agent is designed to act\n",
    "within a particular phase of an overall workflow.\n",
    "\n",
    "The NER agent will need:\n",
    "\n",
    "- the user goal, extended to mention product reviews and what to look for there\n",
    "- a list of markdown files that have been pre-approved\n",
    "- the approved construction plan from the structured data design phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 677
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, you're ready to run the agent. \n",
    "\n",
    "- use the make_agent_caller to create an execution environment\n",
    "- prompt the agent with a single message that should kick-off the analysis\n",
    "- expect the result to be a proposed list of entity types\n",
    "- but *not* a list of approved entity types\n",
    "\n",
    "**The entity types here may vary quite a bit. If you're not happy with the proposal,\n",
    "you can run the cell again to get a new list.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by LLMs can vary with each execution due to their stochastic nature. Your results might differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 405
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "- often, the agent will confuse the process of \"Assembly\" with the resulting thing that is an \"Assembly\"\n",
    "- why is that?\n",
    "- the agent will see the term \"Assembly\" in the list of well-known entity types\n",
    "- and, it will notice complaints about assembling furniture\n",
    "- but, it has no way to know those are two different uses of the word\n",
    "- to fix this, the schema proposal from the previous lesson could save descriptions for each node label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're happy with the proposal, you can tell the agent that you approve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 235
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Fact Type Extraction Sub-agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1. Agent Instructions (fact type extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 303
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 269
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 97
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2. Tool Definitions (fact type extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 881
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 148
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3. Construct the Sub-agent (fact type extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 184
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by LLMs can vary with each execution due to their stochastic nature. Your results might differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 490
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're happy with the fact type proposal, approve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 201
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
